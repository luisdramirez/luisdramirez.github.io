<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Luis D. Ramirez, PhD</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <div class="container">
        <nav class="sidebar">
            <div class="nav-header">
                <h1>Luis D Ramirez, PhD</h1>
            </div>
            <ul class="nav-links">
                <li class="active" data-tab="landing">Home</li>
                <li data-tab="publications">Publications</li>
                <li data-tab="projects">Projects</li>
                <li id="cv-link">CV</li>
            </ul>
        </nav>

        <main class="content">
            <section id="landing" class="tab-content active">
                <div class="fade-group">
                    <p>I'm a researcher focused on understanding how the human brain sees the world. My investigations
                        use psychophysical, computational, and non-invasive neuroimaging approaches.</p>
                    <br>
                    <p>Currently, as a postdoctoral researcher in the <a href="https://serenceslab.ucsd.edu">Serences
                            Lab at UCSD</a>, I'm studying texture encoding and its interaction with sensory and
                        perceptual history.</p>
                    <br>
                    <p>I completed my PhD at Boston University with <a href="https://sites.bu.edu/vision/">Sam Ling</a>.
                        There, I studied the mechanisms underlying <a href="#">temporal attention</a>, and the influence
                        of <a href="https://www.jneurosci.org/content/jneuro/45/25/e0251252025.full.pdf">feature-based
                            attention</a> and <a href="https://doi.org/10.1167/jov.24.10.912">emotion</a> on <a
                            href="https://github.com/luisdramirez/pSF-Toolbox">population spatial frequency tuning</a>.
                    </p>
                    <br>
                    <p>I earned a B.Sc. in Science and Technology Studies at NYU Tandon School of Engineering, where I
                        exposed myself to philosophy and history of science, physics, and neuroscience all in the aim of
                        understanding how the brain, and societies, make sense of reality. I'm grateful that I learned
                        that our understanding of reality (ie physics) is deeply intertwined with our understanding of
                        the brain (ie neuroscience, psychology). You can imagine my surprise when I learned about
                        psychophysics. I quickly sought out hands-on research, and was fortunate enough to gain it in
                        the Carrasco Lab at NYU and the Tong Lab at Vanderbilt University (all while being supported by
                        the NIH BP-ENDURE program).</p>
                    <br>
                    <p>And here we are, more than a decade later.</p>
                    <br>
                    <p><a href="https://scholar.google.com/citations?user=M6b2yYQAAAAJ&hl=en" target="_blank">Google
                            Scholar</a>. <a href="https://github.com/luisdramirez" target="_blank">GitHub</a>.</p>
                </div>
            </section>

            <section id="projects" class="tab-content">
                <div class="fade-group">
                    <div class="project-item">
                        <h3>The Population Spatial Frequency Toolbox (pSF-Toolbox)</h3>
                        <p class="citation"><b>Ramirez, L. D.</b>, Wang, F., Wiecek, E., Vinke, L. N., & Ling, S.
                            2026. The Population Spatial Frequency Toolbox. <i>Journal of Open Research Software</i>.
                            <a href="https://github.com/luisdramirez/pSF-Toolbox" target="_blank">In Press</a>.
                        </p>
                        <p>We developed an <b>open-source MATLAB package</b> to provide a standardized, reproducible
                            pipeline for characterizing spatial frequency (SF) tuning from fMRI data. The toolbox
                            facilitates everything from stimulus generation to voxel-wise parameter optimization,
                            bridging the gap between raw BOLD signals and interpretable neural tuning curves. It
                            includes a <b>measure-pSFT</b> module for Psychtoolbox-based stimulus presentation and an
                            <b>estimate-pSFT</b> module for fitting log-Gaussian models to voxel data. To ensure
                            computational rigor, we included a <b>validation sub-module</b> that uses synthetic BOLD
                            data to benchmark parameter recovery across varying signal-to-noise ratios. This software
                            has been successfully deployed across multiple studies (summarized below).
                        </p>
                    </div>

                    <div class="project-item">
                        <h3>Attention Alters Population Spatial Frequency Tuning</h3>
                        <p class="citation"><b>Ramirez, L. D.</b>, Wang, F. & Ling, S. 2025. Attention alters
                            population spatial frequency tuning. <i>Journal of Neuroscience</i>. <a
                                href="https://doi.org/10.1523/JNEUROSCI.0251-25.2025"
                                target="_blank">https://doi.org/10.1523/JNEUROSCI.0251-25.2025</a>.</p>
                        <p>This project utilized <b>model-based fMRI</b> to investigate how feature-based attention
                            reshapes the SF response profiles of neural populations in the early visual cortex (V1–V3).
                            By measuring these changes in a task-irrelevant hemifield, we were able to isolate the
                            global effects of feature-based attention as they spread across the visual field. We
                            discovered that attention elicits significant <b>"attractive shifts"</b> in SF preference
                            toward the attended frequency, demonstrating that neural populations flexibly adjust their
                            tuning to prioritize task-relevant details. This work provides direct evidence that
                            voluntary attention can dynamically reconfigure the fundamental building blocks of early
                            human vision.</p>
                    </div>

                    <div class="project-item">
                        <h3>Emotional Arousal Alters Population Spatial Frequency Tuning</h3>
                        <p class="citation"><b>Ramirez, L. D.</b>, Pan, J., & Ling, S. 2024. “How does emotional
                            arousal modulate population spatial frequency tuning?” <i>Poster</i>. Vision Sciences
                            Society Conference. <a href="https://doi.org/10.1523/JNEUROSCI.0251-25.2025"
                                target="_blank">https://doi.org/10.1167/jov.24.10.912</a>.</p>
                        <p>This study used <b>pSFT</b> to measure how emotional states reconfigure spatial frequency
                            (SF) processing. Emotional arousal was induced using valenced auditory stimuli while
                            measuring SF tuning in the early visual cortex. Contrary to the long-held belief that
                            negative emotion solely sacrifices fine detail for coarse "gist," we found that negative
                            emotional arousal triggered systematic <b>increases in preferred SF and selectivity</b>,
                            particularly in the extrastriate cortex. In other words, the visual system can dynamically
                            increase spatial resolution to enhance the processing of fine details during high-arousal
                            states.</p>
                    </div>

                    <div class="project-item">
                        <h3>Spatial Frequency Tuning Follows Scale Invariance</h3>
                        <p class="citation">Wiecek, E., <b>Ramirez, L. D.</b>, Klimova, M., & Ling, S. 2026. Spatial
                            frequency tuning follows scale invariance in human visual cortex. <i>Journal of
                                Neuroscience</i>. <a href="https://doi.org/10.1523/JNEUROSCI.1490-25.2025"
                                target="_blank">https://doi.org/10.1523/JNEUROSCI.1490-25.2025</a>.</p>
                        <p>Here we provide a direct test of the <b>scale invariance</b> principle in the human visual
                            cortex—the theory that the resolution of spatial sampling remains constant relative to
                            receptive field (RF) size. By introducing the <b>"Cycles Per Receptive Field" (CPF)</b>
                            metric, we showed that SF preferences scale inversely with population RF size across V1–V3.
                            This project combined <b>population receptive field (pRF) mapping</b> with <b>pSFT</b> to
                            characterize the functional sampling properties of neural populations across the visual
                            field. Our findings validate a fundamental assumption in visual neuroscience and establish a
                            new framework for studying atypical visual development.</p>
                    </div>

                    <div class="project-item">
                        <h3>Temporal Attention Selectively Enhances Target Features</h3>
                        <p class="citation"><b>Ramirez, L. D.</b>, Foster, J. J., & Ling, S. 2021. Temporal attention
                            selectively enhances target features. <i>Journal of Vision</i>. <a
                                href="https://doi.org/10.1167/jov.21.6.6"
                                target="_blank">https://doi.org/10.1167/jov.21.6.6</a>.</p>
                        <p>This research examined the computational mechanisms of <b>temporal attention</b>—the
                            allocation of attention to a specific moment in time. Using a fine-orientation
                            discrimination task paired with an <b>equivalent noise paradigm</b>, we teased apart how
                            attention improves perception under varying levels of external noise. Formal model
                            comparisons revealed that temporal attention acts through a combination of <b>signal and
                                stimulus enhancement</b>, selectively increasing gain for target features. By fitting
                            variants of a <b>divisive normalization model</b> to behavioral data, we provided evidence
                            that the brain can selectively "tune in" to relevant signals even when they are embedded in
                            noise.</p>
                    </div>
                </div>
            </section>

            <section id="publications" class="tab-content">
                <div class="fade-group">
                    <ul class="pub-list">
                        <li>
                            <span class="year">2026</span>
                            <span class="title">The Population Spatial Frequency Toolbox</span>
                            <span class="authors"><b>Ramirez, L. D.</b>, Wang, F., Wiecek, E., Vinke, L. N., & Ling,
                                S.</span>
                            <span class="journal"><i>Journal of Open Research Software</i>. <a
                                    href="https://github.com/luisdramirez/pSF-Toolbox" target="_blank">In
                                    Press.</a></span>
                        </li>
                        <li>
                            <span class="year">2026</span>
                            <span class="title"><a href="https://doi.org/10.1523/JNEUROSCI.1490-25.2025"
                                    target="_blank">Spatial frequency tuning follows scale invariance in human visual
                                    cortex</a></span>
                            <span class="authors">Wiecek, E., <b>Ramirez, L. D.</b>, Klimova, M., & Ling, S.</span>
                            <span class="journal"><i>Journal of Neuroscience</i></span>
                        </li>
                        <li>
                            <span class="year">2025</span>
                            <span class="title"><a href="https://doi.org/10.1523/JNEUROSCI.0251-25.2025"
                                    target="_blank">Attention alters population spatial frequency tuning</a></span>
                            <span class="authors"><b>Ramirez, L. D.</b>, Wang, F. & Ling, S.</span>
                            <span class="journal"><i>Journal of Neuroscience</i></span>
                        </li>
                        <li>
                            <span class="year">2021</span>
                            <span class="title"><a href="https://doi.org/10.1167/jov.21.6.6" target="_blank">Temporal
                                    attention selectively enhances target features</a></span>
                            <span class="authors"><b>Ramirez, L. D.</b>, Foster, J. J., Ling, S.</span>
                            <span class="journal"><i>Journal of Vision</i></span>
                        </li>
                    </ul>
                </div>
            </section>
        </main>
    </div>
    <div id="noise-overlay" class="noise-overlay">
        <svg width="100%" height="100%" xmlns="http://www.w3.org/2000/svg">
            <filter id="noiseFilter">
                <feTurbulence type="fractalNoise" baseFrequency="0.9" numOctaves="1" stitchTiles="stitch"
                    result="noise" />
                <feColorMatrix type="saturate" values="0" in="noise" result="grayNoise" />
                <feComponentTransfer in="grayNoise" result="contrastNoise">
                    <feFuncR type="linear" slope="3" intercept="-1" />
                    <feFuncG type="linear" slope="3" intercept="-1" />
                    <feFuncB type="linear" slope="3" intercept="-1" />
                </feComponentTransfer>
            </filter>
            <rect width="100%" height="100%" filter="url(#noiseFilter)" opacity="1" />
        </svg>
    </div>
    <script src="script.js"></script>
</body>

</html>